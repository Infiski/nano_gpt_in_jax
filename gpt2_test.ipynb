{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee220473c7164287b57dc39deb3460e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b7c7daaf3404d8f87e208d942292e71",
              "IPY_MODEL_5906fe4b6fc14d3d8cd2a3af6027301b",
              "IPY_MODEL_9030e0c67b824a73a53d730fb481f947"
            ],
            "layout": "IPY_MODEL_741909ac8d0a49e1836c235d151e02ed"
          }
        },
        "6b7c7daaf3404d8f87e208d942292e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b77ec7abda24c70bb414d724c07f150",
            "placeholder": "​",
            "style": "IPY_MODEL_9a99e2f380544e40a5af04316eaecd90",
            "value": "config.json: 100%"
          }
        },
        "5906fe4b6fc14d3d8cd2a3af6027301b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b76218c64e544deeb21de14bb1f508c0",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51c5079a3fbf4f8db797d722a848c387",
            "value": 665
          }
        },
        "9030e0c67b824a73a53d730fb481f947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66a56b86724a442cb032702eaec0b819",
            "placeholder": "​",
            "style": "IPY_MODEL_c435e05ab9cf4c2c900dbc74fb1ffc85",
            "value": " 665/665 [00:00&lt;00:00, 80.0kB/s]"
          }
        },
        "741909ac8d0a49e1836c235d151e02ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b77ec7abda24c70bb414d724c07f150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a99e2f380544e40a5af04316eaecd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b76218c64e544deeb21de14bb1f508c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c5079a3fbf4f8db797d722a848c387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66a56b86724a442cb032702eaec0b819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c435e05ab9cf4c2c900dbc74fb1ffc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "863db49101714ab1845bfa0bbed2fa9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d80ba4a1b81e4fb99b8e2e90daf476c8",
              "IPY_MODEL_3a8f5287b8bb4454b580bb601907c4c2",
              "IPY_MODEL_8ea9f60b2b894b1cae0ad8a1d58f396a"
            ],
            "layout": "IPY_MODEL_951ff2d3c512433abed026e262c4dd40"
          }
        },
        "d80ba4a1b81e4fb99b8e2e90daf476c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_120b5034f6584d0fae79db438955a1be",
            "placeholder": "​",
            "style": "IPY_MODEL_9fd8ab1c34364414b8691f9c022c69da",
            "value": "model.safetensors: 100%"
          }
        },
        "3a8f5287b8bb4454b580bb601907c4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bbadc90bb4749be8b1325f2705ae24c",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97469c3a43024839977ea3bbd82d9d0a",
            "value": 548105171
          }
        },
        "8ea9f60b2b894b1cae0ad8a1d58f396a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdc536136304c8c814176eacb7f55ab",
            "placeholder": "​",
            "style": "IPY_MODEL_8dfc648b1fbc49f8a863ee4c23d35e4a",
            "value": " 548M/548M [00:02&lt;00:00, 390MB/s]"
          }
        },
        "951ff2d3c512433abed026e262c4dd40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120b5034f6584d0fae79db438955a1be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fd8ab1c34364414b8691f9c022c69da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bbadc90bb4749be8b1325f2705ae24c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97469c3a43024839977ea3bbd82d9d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bdc536136304c8c814176eacb7f55ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dfc648b1fbc49f8a863ee4c23d35e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "659ef8ff10454b55920f9dfa8d956d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72133e8a44a74a3883ae1175823f6417",
              "IPY_MODEL_2897325617554062836eb0c9db004778",
              "IPY_MODEL_4a64e549db8b44acbe35a3295dadb2b9"
            ],
            "layout": "IPY_MODEL_e5a9d004591e4f8aa419f84da2184c91"
          }
        },
        "72133e8a44a74a3883ae1175823f6417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69e6fb9f14ed48b68409070cfeaeef42",
            "placeholder": "​",
            "style": "IPY_MODEL_4bc130b231234558942f73224a27f5c0",
            "value": "generation_config.json: 100%"
          }
        },
        "2897325617554062836eb0c9db004778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77e41cbdb34e41f9b0f3fb7ee40f3f91",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8cb9ef8c6b344089f6278a7e652c020",
            "value": 124
          }
        },
        "4a64e549db8b44acbe35a3295dadb2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_062c66210a0f4a6ba17acdf8aac9b6ea",
            "placeholder": "​",
            "style": "IPY_MODEL_6261eaae81fa4f92bd1bda83b4e251cf",
            "value": " 124/124 [00:00&lt;00:00, 15.1kB/s]"
          }
        },
        "e5a9d004591e4f8aa419f84da2184c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69e6fb9f14ed48b68409070cfeaeef42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc130b231234558942f73224a27f5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77e41cbdb34e41f9b0f3fb7ee40f3f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cb9ef8c6b344089f6278a7e652c020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "062c66210a0f4a6ba17acdf8aac9b6ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6261eaae81fa4f92bd1bda83b4e251cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCMJJrxtmS25"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "sAButVvZp477"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_hf = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "sd_hf = model_hf.state_dict()\n",
        "\n",
        "# for k, v in sd_hf.items():\n",
        "#   print(k, v.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "ee220473c7164287b57dc39deb3460e3",
            "6b7c7daaf3404d8f87e208d942292e71",
            "5906fe4b6fc14d3d8cd2a3af6027301b",
            "9030e0c67b824a73a53d730fb481f947",
            "741909ac8d0a49e1836c235d151e02ed",
            "5b77ec7abda24c70bb414d724c07f150",
            "9a99e2f380544e40a5af04316eaecd90",
            "b76218c64e544deeb21de14bb1f508c0",
            "51c5079a3fbf4f8db797d722a848c387",
            "66a56b86724a442cb032702eaec0b819",
            "c435e05ab9cf4c2c900dbc74fb1ffc85",
            "863db49101714ab1845bfa0bbed2fa9f",
            "d80ba4a1b81e4fb99b8e2e90daf476c8",
            "3a8f5287b8bb4454b580bb601907c4c2",
            "8ea9f60b2b894b1cae0ad8a1d58f396a",
            "951ff2d3c512433abed026e262c4dd40",
            "120b5034f6584d0fae79db438955a1be",
            "9fd8ab1c34364414b8691f9c022c69da",
            "7bbadc90bb4749be8b1325f2705ae24c",
            "97469c3a43024839977ea3bbd82d9d0a",
            "0bdc536136304c8c814176eacb7f55ab",
            "8dfc648b1fbc49f8a863ee4c23d35e4a",
            "659ef8ff10454b55920f9dfa8d956d58",
            "72133e8a44a74a3883ae1175823f6417",
            "2897325617554062836eb0c9db004778",
            "4a64e549db8b44acbe35a3295dadb2b9",
            "e5a9d004591e4f8aa419f84da2184c91",
            "69e6fb9f14ed48b68409070cfeaeef42",
            "4bc130b231234558942f73224a27f5c0",
            "77e41cbdb34e41f9b0f3fb7ee40f3f91",
            "c8cb9ef8c6b344089f6278a7e652c020",
            "062c66210a0f4a6ba17acdf8aac9b6ea",
            "6261eaae81fa4f92bd1bda83b4e251cf"
          ]
        },
        "id": "4HMwnmJ2qQbf",
        "outputId": "8b92dccd-4775-4edc-be07-4d140a9c8e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee220473c7164287b57dc39deb3460e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "863db49101714ab1845bfa0bbed2fa9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "659ef8ff10454b55920f9dfa8d956d58"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "@dataclass\n",
        "\n",
        "class GPTConfig:\n",
        "  block_size: int = 1024\n",
        "  vocab_size: int = 50257\n",
        "  n_layer: int = 12\n",
        "  n_head: int = 12\n",
        "  n_embed: int = 768\n",
        "  dropout: float = 0.0\n",
        "  bias: bool = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    assert config.n_embed % config.n_head == 0\n",
        "\n",
        "    self.c_attn = nn.Linear(config.n_embed, 3 * config.n_embed)\n",
        "    self.c_proj = nn.Linear(config.n_embed, config.n_embed)\n",
        "    self.c_proj.NANOGPT_SCALE_INIT=1\n",
        "\n",
        "    self.n_head = config.n_head\n",
        "    self.n_embed = config.n_embed\n",
        "\n",
        "    bias = torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "    bias = bias.view(1, 1, config.block_size, config.block_size)\n",
        "\n",
        "    self.register_buffer(\"bias\", bias)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.size()\n",
        "\n",
        "    qkv = self.c_attn(x)\n",
        "\n",
        "    q, k, v = qkv.split(self.n_embed, dim=2)\n",
        "\n",
        "    k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "    q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "    v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "\n",
        "    # att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "    # att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "    # att = F.softmax(att, dim=-1)\n",
        "    # y = att @ v\n",
        "\n",
        "    # Flash attn\n",
        "    y=F.scaled_dot_product_attention(q,k,v,is_causal=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "\n",
        "    y = self.c_proj(y)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.c_fc = nn.Linear(config.n_embed, 4 * config.n_embed)\n",
        "    self.gelu = nn.GELU(approximate='tanh')\n",
        "    self.c_proj = nn.Linear(4*config.n_embed, config.n_embed)\n",
        "    self.c_proj.NANOGPT_SCALE_INIT=1\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.c_fc(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.c_proj(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.ln1 = nn.LayerNorm(config.n_embed)\n",
        "    self.attn = CausalSelfAttention(config)\n",
        "    self.ln2 = nn.LayerNorm(config.n_embed)\n",
        "    self.mlp = MLP(config)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.attn(self.ln1(x))\n",
        "    x = x + self.mlp(self.ln2(x))\n",
        "    return x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "\n",
        "    self.transformer = nn.ModuleDict(dict(\n",
        "        wte = nn.Embedding(config.vocab_size, config.n_embed),\n",
        "        wpe = nn.Embedding(config.block_size, config.n_embed),\n",
        "        h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "        ln_f = nn.LayerNorm(config.n_embed)\n",
        "\n",
        "    ))\n",
        "\n",
        "    self.lm_head = nn.Linear(config.n_embed, config.vocab_size, bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    self.transformer.wte.weight = self.lm_head.weight\n",
        "\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    if isinstance(module, nn.Linear):\n",
        "      std=0.02\n",
        "      if hasattr(module, \"NANOGPT_SCALE_INIT\"):\n",
        "        std *= (2 * self.config.n_layer) ** -0.5\n",
        "\n",
        "      torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "      if module.bias is not None:\n",
        "        torch.nn.init.zeros_(module.bias)\n",
        "    elif isinstance(module, nn.Embedding):\n",
        "      torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    B, T = idx.size()\n",
        "    assert T <= self.config.block_size, f\"Cannot forward sequence of length {T}, block size is only {self.config.block_size}\"\n",
        "\n",
        "    pos = torch.arange(0, T, dtype=torch.long, device=idx.device)\n",
        "    pos_emb = self.transformer.wpe(pos)\n",
        "\n",
        "    tok_emb = self.transformer.wte(idx)\n",
        "\n",
        "    x = tok_emb + pos_emb\n",
        "    for block in self.transformer.h:\n",
        "      x = block(x)\n",
        "\n",
        "    x = self.transformer.ln_f(x)\n",
        "    logits = self.lm_head(x)\n",
        "    loss = None\n",
        "    if targets is not None:\n",
        "      loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "\n",
        "\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  @classmethod\n",
        "  def from_pretrained(cls, model_type: str):\n",
        "      assert model_type in [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\"]\n",
        "\n",
        "      from transformers import GPT2LMHeadModel\n",
        "\n",
        "      # minimal config map\n",
        "      hf_cfg = {\n",
        "          \"gpt2\":        dict(n_layer=12, n_head=12, n_embed=768),\n",
        "          \"gpt2-medium\": dict(n_layer=24, n_head=16, n_embed=1024),\n",
        "          \"gpt2-large\":  dict(n_layer=36, n_head=20, n_embed=1280),\n",
        "          \"gpt2-xl\":     dict(n_layer=48, n_head=25, n_embed=1600),\n",
        "      }[model_type]\n",
        "\n",
        "      cfg = GPTConfig(**hf_cfg, vocab_size=50257, block_size=1024)\n",
        "      model = cls(cfg)\n",
        "\n",
        "      # load HF\n",
        "      hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "      sd_hf = hf.state_dict()  # keys like 'transformer.h.0.ln_1.weight', etc.\n",
        "\n",
        "      # build a mapping from *our* key -> *HF* key\n",
        "      def map_key_ours_to_hf(k: str) -> str | None:\n",
        "          # ignore our registered buffer for the mask\n",
        "          if k.endswith(\".attn.bias\"):\n",
        "              return None\n",
        "\n",
        "          # embeddings\n",
        "          if k == \"transformer.wte.weight\": return \"transformer.wte.weight\"\n",
        "          if k == \"transformer.wpe.weight\": return \"transformer.wpe.weight\"\n",
        "\n",
        "          # final layernorm\n",
        "          if k == \"transformer.ln_f.weight\": return \"transformer.ln_f.weight\"\n",
        "          if k == \"transformer.ln_f.bias\":   return \"transformer.ln_f.bias\"\n",
        "\n",
        "          # lm head\n",
        "          if k == \"lm_head.weight\": return \"lm_head.weight\"\n",
        "\n",
        "          # blocks\n",
        "          # ours:  transformer.h.{i}.(ln1|ln2|attn.*|mlp.*).(weight|bias)\n",
        "          # hf:    transformer.h.{i}.(ln_1|ln_2|attn.*|mlp.*).(weight|bias)\n",
        "          if k.startswith(\"transformer.h.\"):\n",
        "              parts = k.split(\".\")\n",
        "              # e.g. ['transformer','h','0','ln1','weight']\n",
        "              i = parts[2]\n",
        "              sub = parts[3]\n",
        "\n",
        "              # layer norms\n",
        "              if sub == \"ln1\":\n",
        "                  return f\"transformer.h.{i}.ln_1.{parts[4]}\"\n",
        "              if sub == \"ln2\":\n",
        "                  return f\"transformer.h.{i}.ln_2.{parts[4]}\"\n",
        "\n",
        "              # attention\n",
        "              if sub == \"attn\":\n",
        "                  # c_attn / c_proj names are the same in HF\n",
        "                  return f\"transformer.h.{i}.attn.{parts[4]}.{parts[5]}\"\n",
        "\n",
        "              # mlp\n",
        "              if sub == \"mlp\":\n",
        "                  # c_fc / c_proj names are the same\n",
        "                  return f\"transformer.h.{i}.mlp.{parts[4]}.{parts[5]}\"\n",
        "\n",
        "          # fallback: no mapping\n",
        "          return None\n",
        "\n",
        "      # which weights need a transpose (HF Conv1D -> our Linear)\n",
        "      needs_T = (\n",
        "          \"attn.c_attn.weight\",\n",
        "          \"attn.c_proj.weight\",\n",
        "          \"mlp.c_fc.weight\",\n",
        "          \"mlp.c_proj.weight\",\n",
        "      )\n",
        "\n",
        "      sd_ours = model.state_dict()\n",
        "      with torch.no_grad():\n",
        "          for k_ours in sd_ours.keys():\n",
        "              k_hf = map_key_ours_to_hf(k_ours)\n",
        "              if k_hf is None:\n",
        "                  # ignore buffers like the causal mask\n",
        "                  continue\n",
        "              if k_hf not in sd_hf:\n",
        "                  raise KeyError(f\"HF key missing for our key {k_ours!r} -> {k_hf!r}\")\n",
        "\n",
        "              w_src = sd_hf[k_hf]\n",
        "              w_dst = sd_ours[k_ours]\n",
        "\n",
        "              # transpose if needed\n",
        "              if any(k_ours.endswith(s) for s in needs_T):\n",
        "                  if w_src.ndim != 2:\n",
        "                      raise ValueError(f\"Expected 2D for transposed weight: {k_hf} got {w_src.shape}\")\n",
        "                  w_src = w_src.t()\n",
        "\n",
        "              if w_src.shape != w_dst.shape:\n",
        "                  raise ValueError(f\"Shape mismatch: {k_ours}: dst {w_dst.shape} vs src {w_src.shape} (from {k_hf})\")\n",
        "\n",
        "              w_dst.copy_(w_src)\n",
        "\n",
        "      model.load_state_dict(sd_ours)\n",
        "      return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zvsIoTAZqc2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "\n",
        "class DataLoaderLite:\n",
        "    def __init__(self, B, T, filename=\"/content/input.txt\", max_chars=1000):\n",
        "        self.B = B\n",
        "        self.T = T\n",
        "\n",
        "        # load and tokenize once at init\n",
        "        with open(filename, \"r\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "\n",
        "        enc = tiktoken.get_encoding(\"gpt2\")\n",
        "        self.tokens = torch.tensor(enc.encode(text), dtype=torch.long)\n",
        "\n",
        "        print(f\"loaded {len(self.tokens)} tokens\")\n",
        "        print(f\"1 epoch = {len(self.tokens) // (B*T)} batches\")\n",
        "\n",
        "        self.current_position = 0\n",
        "\n",
        "    def next_batch(self):\n",
        "        B, T = self.B, self.T\n",
        "\n",
        "        # slice out B*T+1 tokens so we can make (x,y) pairs\n",
        "        buf = self.tokens[self.current_position : self.current_position + B*T + 1]\n",
        "\n",
        "        x = buf[:-1].view(B, T)\n",
        "        y = buf[1: ].view(B, T)\n",
        "\n",
        "        self.current_position += B*T\n",
        "        if self.current_position + B*T + 1 >= len(self.tokens):\n",
        "            self.current_position = 0\n",
        "\n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "YHEb0_e8IGzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT.from_pretrained('gpt2')\n",
        "print('all okay')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6sGz7A71jIy",
        "outputId": "d50a5073-4f2c-44e2-a812-ef3586c8f234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all okay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch_xla.core.xla_model as xm\n",
        "\n",
        "# device = xm.xla_device()\n",
        "# print(device)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ],
      "metadata": {
        "id": "6hYvnK7J5Ocs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AYRbPwvP5OZw",
        "outputId": "e165f44a-7770-4c60-8832-d63b83939dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xzsC2p21xVE",
        "outputId": "2937ff74-a311-482c-ca13-8b4b47280bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT(\n",
              "  (transformer): ModuleDict(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x Block(\n",
              "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): CausalSelfAttention(\n",
              "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): GELU(approximate='tanh')\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zO6kdvC5-WL",
        "outputId": "0f0860eb-d995-4120-cb59-8fc15bf57351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.7.34)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
            "Downloading tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_return_sequences = 5\n",
        "max_len = 30\n",
        "\n",
        "import tiktoken, math\n",
        "enc= tiktoken.get_encoding(\"gpt2\")\n",
        "tokens = enc.encode(\"hi how are you , \")\n",
        "tokens = torch.tensor(tokens, dtype=torch.long, device=device)\n",
        "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
        "x= tokens.to(device)\n",
        "# seed=42\n",
        "# xm.set_rng_state(seed, xm.xla_device())\n",
        "torch.manual_seed(42)\n",
        "\n",
        "while x.size(1) < max_len:\n",
        "  with torch.no_grad():\n",
        "    logits = model(x)\n",
        "    logits = logits[:, -1, :]\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    topk_probs, topk_indices = torch.topk(probs, k=5, dim=-1)\n",
        "    ix = torch.multinomial(topk_probs, num_samples=1)\n",
        "    xcol = torch.gather(topk_indices, dim=-1, index=ix)\n",
        "    x = torch.cat((x, xcol), dim=1)\n",
        "\n",
        "# %%time\n",
        "for i in range(num_return_sequences):\n",
        "  tokens = x[i, :max_len].tolist()\n",
        "  decoded = enc.decode(tokens)\n",
        "  print(decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQbSnZPc6JqE",
        "outputId": "c2c1651d-7044-473f-aa33-6fa5edc49227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi how are you , ?\"\n",
            "\n",
            "\"You're a good person, !\"\n",
            "\n",
            "\"You're very nice and polite. !\"\n",
            "hi how are you ,  I have a problem with you,  but I am not going to tell you why, I will just tell\n",
            "hi how are you ,  you're not doing anything  that is going to change the world,  and you're not going to\n",
            "hi how are you ,  so we can all get along and enjoy the game!\n",
            "The game was released in Japan on November 3rd,\n",
            "hi how are you , ????\n",
            "\n",
            "I don't know how you're gonna get your name, ????\n",
            "\n",
            "I don't know if\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/input.txt', 'r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "data = text[:1000]\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBpr6NQd6Veo",
        "outputId": "2e5a09a2-752e-4d7f-eb76-e356691a9795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "enc = tiktoken.get_encoding('gpt2')\n",
        "tokens = enc.encode(data)\n",
        "print(tokens[:24])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Grgw-Php65Mg",
        "outputId": "edf219dc-47d3-43d2-f7ef-e084003fb8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5962, 22307, 25, 198, 8421, 356, 5120, 597, 2252, 11, 3285, 502, 2740, 13, 198, 198, 3237, 25, 198, 5248, 461, 11, 2740, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "buf = torch.tensor(tokens[:24+1])\n",
        "\n",
        "x = buf[:-1].view(4, 6)\n",
        "y = buf[1:].view(4, 6)\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPqSlXG665KK",
        "outputId": "1d87053e-79f0-4f56-cd4c-00f66b063d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5962, 22307,    25,   198,  8421,   356],\n",
            "        [ 5120,   597,  2252,    11,  3285,   502],\n",
            "        [ 2740,    13,   198,   198,  3237,    25],\n",
            "        [  198,  5248,   461,    11,  2740,    13]])\n",
            "tensor([[22307,    25,   198,  8421,   356,  5120],\n",
            "        [  597,  2252,    11,  3285,   502,  2740],\n",
            "        [   13,   198,   198,  3237,    25,   198],\n",
            "        [ 5248,   461,    11,  2740,    13,   198]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "with open('/content/input.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "text = text[:1000]\n",
        "tokens = enc.encode(text)\n",
        "B, T = 4, 32\n",
        "buf = torch.tensor(tokens[:B*T + 1])\n",
        "x = buf[:-1].view(B, T).to(device)\n",
        "y = buf[1:].view(B, T).to(device)\n"
      ],
      "metadata": {
        "id": "ul56cEd565Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=GPT(GPTConfig())\n",
        "model.to(device)\n",
        "logits, loss = model(x, y)\n",
        "print(loss)\n",
        "print(logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu1n9Y1TC0Q4",
        "outputId": "6e9abda0-36c7-4573-cb18-5f0e8fad1eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.9952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "torch.Size([4, 32, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoaderLite(B=8, T=1024)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZRXL8jMIqBu",
        "outputId": "83098289-a4f1-4f56-fb2a-e473fdd1cda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 338025 tokens\n",
            "1 epoch = 41 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# normal training"
      ],
      "metadata": {
        "id": "wgZXFdySYcAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time, math\n",
        "train_loader = DataLoaderLite(B=8, T=1024)\n",
        "model=GPT(GPTConfig())\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "for i in range(50):\n",
        "  t0=time.time()\n",
        "  x, y = train_loader.next_batch()\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  logits, loss = model(x, y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  torch.cuda.synchronize()\n",
        "  t1=time.time()\n",
        "  dt = (t1-t0) * 1000\n",
        "  tokens_per_sec = (train_loader.B + train_loader.T) / (t1-t0)\n",
        "  print(f\"step{i} , loss {loss.item()} , time {dt:.2f} ms, tokens/sec {tokens_per_sec:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXZ0wkwgC37_",
        "outputId": "dbb22a95-c0a9-44c2-ed13-8efd520b90f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 338025 tokens\n",
            "1 epoch = 41 batches\n",
            "step0 , loss 11.137648582458496 , time 932.85 ms, tokens/sec 1106.29\n",
            "step1 , loss 9.672666549682617 , time 932.55 ms, tokens/sec 1106.64\n",
            "step2 , loss 8.906072616577148 , time 936.65 ms, tokens/sec 1101.79\n",
            "step3 , loss 8.671490669250488 , time 935.73 ms, tokens/sec 1102.88\n",
            "step4 , loss 8.507978439331055 , time 933.56 ms, tokens/sec 1105.45\n",
            "step5 , loss 8.427803039550781 , time 934.19 ms, tokens/sec 1104.70\n",
            "step6 , loss 8.361255645751953 , time 935.96 ms, tokens/sec 1102.61\n",
            "step7 , loss 8.01619815826416 , time 935.50 ms, tokens/sec 1103.15\n",
            "step8 , loss 7.736024856567383 , time 937.84 ms, tokens/sec 1100.40\n",
            "step9 , loss 7.6974639892578125 , time 938.01 ms, tokens/sec 1100.20\n",
            "step10 , loss 7.671797275543213 , time 936.94 ms, tokens/sec 1101.46\n",
            "step11 , loss 7.495182037353516 , time 938.55 ms, tokens/sec 1099.57\n",
            "step12 , loss 7.4293036460876465 , time 938.68 ms, tokens/sec 1099.41\n",
            "step13 , loss 7.186164855957031 , time 939.17 ms, tokens/sec 1098.84\n",
            "step14 , loss 7.084506034851074 , time 938.81 ms, tokens/sec 1099.27\n",
            "step15 , loss 6.873124599456787 , time 943.43 ms, tokens/sec 1093.88\n",
            "step16 , loss 6.756949424743652 , time 943.32 ms, tokens/sec 1094.00\n",
            "step17 , loss 6.7645955085754395 , time 941.35 ms, tokens/sec 1096.30\n",
            "step18 , loss 6.647914409637451 , time 939.70 ms, tokens/sec 1098.22\n",
            "step19 , loss 6.465685844421387 , time 942.81 ms, tokens/sec 1094.60\n",
            "step20 , loss 6.520549774169922 , time 944.32 ms, tokens/sec 1092.85\n",
            "step21 , loss 6.376684188842773 , time 948.87 ms, tokens/sec 1087.61\n",
            "step22 , loss 6.469161033630371 , time 945.17 ms, tokens/sec 1091.87\n",
            "step23 , loss 6.317389488220215 , time 943.16 ms, tokens/sec 1094.19\n",
            "step24 , loss 6.316280364990234 , time 949.16 ms, tokens/sec 1087.28\n",
            "step25 , loss 6.4050188064575195 , time 941.93 ms, tokens/sec 1095.62\n",
            "step26 , loss 6.602578639984131 , time 942.10 ms, tokens/sec 1095.43\n",
            "step27 , loss 6.503194332122803 , time 943.69 ms, tokens/sec 1093.58\n",
            "step28 , loss 6.741887092590332 , time 946.40 ms, tokens/sec 1090.45\n",
            "step29 , loss 6.5132341384887695 , time 947.64 ms, tokens/sec 1089.03\n",
            "step30 , loss 6.51356840133667 , time 943.06 ms, tokens/sec 1094.32\n",
            "step31 , loss 6.5048723220825195 , time 944.17 ms, tokens/sec 1093.02\n",
            "step32 , loss 6.360566139221191 , time 948.46 ms, tokens/sec 1088.08\n",
            "step33 , loss 6.685761451721191 , time 942.07 ms, tokens/sec 1095.46\n",
            "step34 , loss 6.542922496795654 , time 942.18 ms, tokens/sec 1095.33\n",
            "step35 , loss 6.4391398429870605 , time 942.80 ms, tokens/sec 1094.61\n",
            "step36 , loss 6.4991350173950195 , time 943.35 ms, tokens/sec 1093.98\n",
            "step37 , loss 6.503519058227539 , time 942.85 ms, tokens/sec 1094.55\n",
            "step38 , loss 6.274816513061523 , time 942.64 ms, tokens/sec 1094.80\n",
            "step39 , loss 6.313210964202881 , time 939.77 ms, tokens/sec 1098.14\n",
            "step40 , loss 6.543929576873779 , time 938.30 ms, tokens/sec 1099.86\n",
            "step41 , loss 6.300238132476807 , time 940.60 ms, tokens/sec 1097.17\n",
            "step42 , loss 6.365235328674316 , time 940.15 ms, tokens/sec 1097.69\n",
            "step43 , loss 6.074805736541748 , time 940.69 ms, tokens/sec 1097.07\n",
            "step44 , loss 6.008309364318848 , time 939.11 ms, tokens/sec 1098.92\n",
            "step45 , loss 6.093975067138672 , time 939.02 ms, tokens/sec 1099.01\n",
            "step46 , loss 6.217728614807129 , time 940.29 ms, tokens/sec 1097.54\n",
            "step47 , loss 6.183171272277832 , time 938.16 ms, tokens/sec 1100.03\n",
            "step48 , loss 6.05424690246582 , time 939.23 ms, tokens/sec 1098.77\n",
            "step49 , loss 5.905754089355469 , time 937.26 ms, tokens/sec 1101.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BF 32 training"
      ],
      "metadata": {
        "id": "SWzRUApjYvY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "train_loader = DataLoaderLite(B=8, T=1024)\n",
        "torch.set_float32_matmul_precision('high')\n",
        "model=GPT(GPTConfig())\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "for i in range(50):\n",
        "  t0=time.time()\n",
        "  x, y = train_loader.next_batch()\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  logits, loss = model(x, y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  torch.cuda.synchronize()\n",
        "  t1=time.time()\n",
        "  dt = (t1-t0) * 1000\n",
        "  tokens_per_sec = (train_loader.B + train_loader.T) / (t1-t0)\n",
        "  print(f\"step{i} , loss {loss.item()} , time {dt:.2f} ms, tokens/sec {tokens_per_sec:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq6ktApYC35I",
        "outputId": "0029cfb1-0823-4fb4-fa63-44ff6f29ff86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 338025 tokens\n",
            "1 epoch = 41 batches\n",
            "step0 , loss 10.963109970092773 , time 934.57 ms, tokens/sec 1104.25\n",
            "step1 , loss 9.52399730682373 , time 935.68 ms, tokens/sec 1102.94\n",
            "step2 , loss 8.894760131835938 , time 932.21 ms, tokens/sec 1107.05\n",
            "step3 , loss 8.691394805908203 , time 936.00 ms, tokens/sec 1102.57\n",
            "step4 , loss 8.559069633483887 , time 936.77 ms, tokens/sec 1101.66\n",
            "step5 , loss 8.408178329467773 , time 934.04 ms, tokens/sec 1104.87\n",
            "step6 , loss 8.351126670837402 , time 933.51 ms, tokens/sec 1105.51\n",
            "step7 , loss 8.024391174316406 , time 934.55 ms, tokens/sec 1104.28\n",
            "step8 , loss 7.745752334594727 , time 934.25 ms, tokens/sec 1104.63\n",
            "step9 , loss 7.717187881469727 , time 932.82 ms, tokens/sec 1106.32\n",
            "step10 , loss 7.703033924102783 , time 932.40 ms, tokens/sec 1106.83\n",
            "step11 , loss 7.492473125457764 , time 933.09 ms, tokens/sec 1106.00\n",
            "step12 , loss 7.4355902671813965 , time 933.26 ms, tokens/sec 1105.80\n",
            "step13 , loss 7.245229244232178 , time 932.52 ms, tokens/sec 1106.68\n",
            "step14 , loss 7.133626937866211 , time 934.31 ms, tokens/sec 1104.56\n",
            "step15 , loss 6.97419548034668 , time 932.39 ms, tokens/sec 1106.83\n",
            "step16 , loss 6.8730669021606445 , time 934.64 ms, tokens/sec 1104.17\n",
            "step17 , loss 6.856659412384033 , time 935.94 ms, tokens/sec 1102.64\n",
            "step18 , loss 6.733773231506348 , time 933.32 ms, tokens/sec 1105.72\n",
            "step19 , loss 6.600686073303223 , time 933.34 ms, tokens/sec 1105.71\n",
            "step20 , loss 6.653046607971191 , time 932.94 ms, tokens/sec 1106.18\n",
            "step21 , loss 6.529335975646973 , time 935.71 ms, tokens/sec 1102.91\n",
            "step22 , loss 6.6095685958862305 , time 935.25 ms, tokens/sec 1103.45\n",
            "step23 , loss 6.477952003479004 , time 932.65 ms, tokens/sec 1106.52\n",
            "step24 , loss 6.458312034606934 , time 933.47 ms, tokens/sec 1105.56\n",
            "step25 , loss 6.504961013793945 , time 934.40 ms, tokens/sec 1104.45\n",
            "step26 , loss 6.622195243835449 , time 933.15 ms, tokens/sec 1105.93\n",
            "step27 , loss 6.5180511474609375 , time 932.75 ms, tokens/sec 1106.41\n",
            "step28 , loss 6.761213302612305 , time 935.98 ms, tokens/sec 1102.59\n",
            "step29 , loss 6.565446376800537 , time 934.31 ms, tokens/sec 1104.56\n",
            "step30 , loss 6.564199924468994 , time 933.32 ms, tokens/sec 1105.73\n",
            "step31 , loss 6.5641679763793945 , time 933.40 ms, tokens/sec 1105.64\n",
            "step32 , loss 6.391421318054199 , time 936.94 ms, tokens/sec 1101.46\n",
            "step33 , loss 6.73548698425293 , time 935.37 ms, tokens/sec 1103.31\n",
            "step34 , loss 6.596309661865234 , time 933.29 ms, tokens/sec 1105.76\n",
            "step35 , loss 6.480880260467529 , time 933.47 ms, tokens/sec 1105.56\n",
            "step36 , loss 6.544942855834961 , time 935.96 ms, tokens/sec 1102.62\n",
            "step37 , loss 6.550810813903809 , time 937.01 ms, tokens/sec 1101.38\n",
            "step38 , loss 6.330714702606201 , time 933.27 ms, tokens/sec 1105.79\n",
            "step39 , loss 6.3639655113220215 , time 933.66 ms, tokens/sec 1105.33\n",
            "step40 , loss 6.622624397277832 , time 935.65 ms, tokens/sec 1102.98\n",
            "step41 , loss 6.373309135437012 , time 935.84 ms, tokens/sec 1102.75\n",
            "step42 , loss 6.395717620849609 , time 935.72 ms, tokens/sec 1102.89\n",
            "step43 , loss 6.126684665679932 , time 935.68 ms, tokens/sec 1102.94\n",
            "step44 , loss 6.067049980163574 , time 934.28 ms, tokens/sec 1104.59\n",
            "step45 , loss 6.149919033050537 , time 936.36 ms, tokens/sec 1102.14\n",
            "step46 , loss 6.267023086547852 , time 938.65 ms, tokens/sec 1099.45\n",
            "step47 , loss 6.2445068359375 , time 937.65 ms, tokens/sec 1100.63\n",
            "step48 , loss 6.1347761154174805 , time 937.68 ms, tokens/sec 1100.59\n",
            "step49 , loss 5.993071556091309 , time 936.00 ms, tokens/sec 1102.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# scaler = GradScaler()\n",
        "\n",
        "# for i in range(50):\n",
        "#     t0 = time.time()\n",
        "#     x, y = train_loader.next_batch()\n",
        "#     x = x.to(device, non_blocking=True)\n",
        "#     y = y.to(device, non_blocking=True)\n",
        "\n",
        "#     optimizer.zero_grad(set_to_none=True)\n",
        "#     with autocast(dtype=torch.float16):          # FP16 compute\n",
        "#         logits, loss = model(x, y)\n",
        "\n",
        "#     scaler.scale(loss).backward()\n",
        "#     scaler.step(optimizer)\n",
        "#     scaler.update()\n",
        "\n",
        "#     # for fair timing:\n",
        "#     torch.cuda.synchronize()\n",
        "#     t1 = time.time()\n",
        "\n",
        "#     dt_ms = (t1 - t0) * 1000\n",
        "#     tokens = train_loader.B * train_loader.T     # not B+T\n",
        "#     tps = tokens / (t1 - t0)\n",
        "#     print(f\"step {i}, loss {loss.item():.4f}, time {dt_ms:.2f} ms, tokens/s {tps:.1f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iwff7sBsC31G",
        "outputId": "f9f0466d-0bfa-45ac-e0a8-1e3c955d2815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1739636857.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-1739636857.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(dtype=torch.float16):          # FP16 compute\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0, loss 6.7530, time 419.87 ms, tokens/s 4877.7\n",
            "step 1, loss 6.6962, time 223.31 ms, tokens/s 9171.3\n",
            "step 2, loss 6.7090, time 221.67 ms, tokens/s 9238.8\n",
            "step 3, loss 6.4120, time 221.87 ms, tokens/s 9230.6\n",
            "step 4, loss 6.4810, time 221.78 ms, tokens/s 9234.4\n",
            "step 5, loss 6.6615, time 223.67 ms, tokens/s 9156.3\n",
            "step 6, loss 6.6375, time 223.40 ms, tokens/s 9167.3\n",
            "step 7, loss 6.4719, time 220.86 ms, tokens/s 9273.0\n",
            "step 8, loss 6.4212, time 220.35 ms, tokens/s 9294.4\n",
            "step 9, loss 6.3914, time 223.72 ms, tokens/s 9154.3\n",
            "step 10, loss 6.2609, time 221.94 ms, tokens/s 9227.9\n",
            "step 11, loss 6.2923, time 221.62 ms, tokens/s 9241.2\n",
            "step 12, loss 6.1004, time 222.05 ms, tokens/s 9223.3\n",
            "step 13, loss 6.3277, time 222.62 ms, tokens/s 9199.5\n",
            "step 14, loss 6.3900, time 223.54 ms, tokens/s 9161.5\n",
            "step 15, loss 6.4900, time 223.41 ms, tokens/s 9166.9\n",
            "step 16, loss 6.6758, time 222.82 ms, tokens/s 9191.4\n",
            "step 17, loss 6.5570, time 222.25 ms, tokens/s 9214.7\n",
            "step 18, loss 6.7468, time 221.88 ms, tokens/s 9230.2\n",
            "step 19, loss 6.4369, time 224.31 ms, tokens/s 9130.4\n",
            "step 20, loss 6.2460, time 224.58 ms, tokens/s 9119.4\n",
            "step 21, loss 6.8476, time 223.63 ms, tokens/s 9158.1\n",
            "step 22, loss 6.3488, time 222.77 ms, tokens/s 9193.4\n",
            "step 23, loss 6.3243, time 222.96 ms, tokens/s 9185.6\n",
            "step 24, loss 6.4436, time 225.88 ms, tokens/s 9066.7\n",
            "step 25, loss 6.4782, time 224.62 ms, tokens/s 9117.5\n",
            "step 26, loss 6.3999, time 224.88 ms, tokens/s 9107.1\n",
            "step 27, loss 6.1108, time 224.02 ms, tokens/s 9142.0\n",
            "step 28, loss 6.0780, time 225.17 ms, tokens/s 9095.5\n",
            "step 29, loss 6.1127, time 225.03 ms, tokens/s 9100.9\n",
            "step 30, loss 6.1858, time 224.95 ms, tokens/s 9104.1\n",
            "step 31, loss 6.2232, time 223.07 ms, tokens/s 9181.2\n",
            "step 32, loss 6.4216, time 223.86 ms, tokens/s 9148.4\n",
            "step 33, loss 6.1696, time 226.39 ms, tokens/s 9046.5\n",
            "step 34, loss 6.2219, time 223.28 ms, tokens/s 9172.5\n",
            "step 35, loss 6.2631, time 227.74 ms, tokens/s 8992.8\n",
            "step 36, loss 6.1677, time 223.24 ms, tokens/s 9173.9\n",
            "step 37, loss 6.2990, time 222.83 ms, tokens/s 9190.8\n",
            "step 38, loss 6.3749, time 223.34 ms, tokens/s 9169.8\n",
            "step 39, loss 6.4235, time 225.59 ms, tokens/s 9078.6\n",
            "step 40, loss 6.2139, time 224.53 ms, tokens/s 9121.5\n",
            "step 41, loss 6.3157, time 225.13 ms, tokens/s 9097.1\n",
            "step 42, loss 6.2379, time 222.60 ms, tokens/s 9200.5\n",
            "step 43, loss 6.0454, time 222.22 ms, tokens/s 9216.1\n",
            "step 44, loss 5.9408, time 224.22 ms, tokens/s 9133.8\n",
            "step 45, loss 6.3718, time 224.30 ms, tokens/s 9130.7\n",
            "step 46, loss 6.1312, time 225.02 ms, tokens/s 9101.4\n",
            "step 47, loss 6.1502, time 226.09 ms, tokens/s 9058.2\n",
            "step 48, loss 6.0410, time 226.72 ms, tokens/s 9033.2\n",
            "step 49, loss 6.0044, time 225.46 ms, tokens/s 9083.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hw4LpLa8UBhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixed precision T4 doesnt support but supports L4"
      ],
      "metadata": {
        "id": "Ww6XO4X8U86b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "gLR0Q-UqU8cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "train_loader = DataLoaderLite(B=8, T=1024)\n",
        "# torch.set_float32_matmul_precision('high')\n",
        "model=GPT(GPTConfig())\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "for i in range(50):\n",
        "  t0=time.time()\n",
        "  x, y = train_loader.next_batch()\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  torch.cuda.synchronize()\n",
        "  t1=time.time()\n",
        "  dt = (t1-t0) * 1000\n",
        "  tokens_per_sec = (train_loader.B + train_loader.T) / (t1-t0)\n",
        "  print(f\"step{i} , loss {loss.item()} , time {dt:.2f} ms, tokens/sec {tokens_per_sec:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV_Q2BpXU8Zj",
        "outputId": "046116a3-9ca9-48d9-91ea-2e2937e1c46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 338025 tokens\n",
            "1 epoch = 41 batches\n",
            "step0 , loss 11.059371948242188 , time 749.88 ms, tokens/sec 1376.22\n",
            "step1 , loss 9.565448760986328 , time 750.11 ms, tokens/sec 1375.80\n",
            "step2 , loss 9.601821899414062 , time 747.63 ms, tokens/sec 1380.36\n",
            "step3 , loss 8.694334030151367 , time 747.59 ms, tokens/sec 1380.43\n",
            "step4 , loss 8.53415584564209 , time 746.87 ms, tokens/sec 1381.76\n",
            "step5 , loss 8.528876304626465 , time 747.66 ms, tokens/sec 1380.31\n",
            "step6 , loss 8.43848991394043 , time 746.75 ms, tokens/sec 1381.98\n",
            "step7 , loss 8.079373359680176 , time 747.27 ms, tokens/sec 1381.03\n",
            "step8 , loss 7.797780990600586 , time 748.86 ms, tokens/sec 1378.09\n",
            "step9 , loss 7.75493049621582 , time 746.60 ms, tokens/sec 1382.27\n",
            "step10 , loss 7.741931915283203 , time 744.58 ms, tokens/sec 1386.02\n",
            "step11 , loss 7.585170745849609 , time 748.80 ms, tokens/sec 1378.20\n",
            "step12 , loss 7.533687591552734 , time 747.13 ms, tokens/sec 1381.28\n",
            "step13 , loss 7.325366973876953 , time 747.58 ms, tokens/sec 1380.46\n",
            "step14 , loss 7.206825256347656 , time 747.34 ms, tokens/sec 1380.90\n",
            "step15 , loss 7.021024703979492 , time 748.54 ms, tokens/sec 1378.68\n",
            "step16 , loss 6.910411834716797 , time 749.25 ms, tokens/sec 1377.38\n",
            "step17 , loss 6.895448684692383 , time 747.32 ms, tokens/sec 1380.93\n",
            "step18 , loss 6.773465156555176 , time 750.21 ms, tokens/sec 1375.61\n",
            "step19 , loss 6.648828506469727 , time 746.96 ms, tokens/sec 1381.61\n",
            "step20 , loss 6.702942848205566 , time 748.61 ms, tokens/sec 1378.55\n",
            "step21 , loss 6.584721565246582 , time 748.20 ms, tokens/sec 1379.31\n",
            "step22 , loss 6.660335540771484 , time 748.17 ms, tokens/sec 1379.36\n",
            "step23 , loss 6.552827835083008 , time 748.27 ms, tokens/sec 1379.19\n",
            "step24 , loss 6.530862808227539 , time 749.42 ms, tokens/sec 1377.07\n",
            "step25 , loss 6.59149169921875 , time 749.56 ms, tokens/sec 1376.80\n",
            "step26 , loss 6.687009811401367 , time 748.00 ms, tokens/sec 1379.68\n",
            "step27 , loss 6.593610763549805 , time 749.87 ms, tokens/sec 1376.23\n",
            "step28 , loss 6.798185348510742 , time 747.19 ms, tokens/sec 1381.18\n",
            "step29 , loss 6.6385955810546875 , time 750.08 ms, tokens/sec 1375.85\n",
            "step30 , loss 6.622005462646484 , time 747.42 ms, tokens/sec 1380.75\n",
            "step31 , loss 6.65427303314209 , time 749.52 ms, tokens/sec 1376.89\n",
            "step32 , loss 6.529036521911621 , time 747.75 ms, tokens/sec 1380.14\n",
            "step33 , loss 6.827966690063477 , time 748.83 ms, tokens/sec 1378.15\n",
            "step34 , loss 6.717859268188477 , time 748.89 ms, tokens/sec 1378.04\n",
            "step35 , loss 6.626923561096191 , time 748.74 ms, tokens/sec 1378.32\n",
            "step36 , loss 6.6791181564331055 , time 748.47 ms, tokens/sec 1378.82\n",
            "step37 , loss 6.71230411529541 , time 748.75 ms, tokens/sec 1378.30\n",
            "step38 , loss 6.504616737365723 , time 749.87 ms, tokens/sec 1376.25\n",
            "step39 , loss 6.549337387084961 , time 748.51 ms, tokens/sec 1378.73\n",
            "step40 , loss 6.699440002441406 , time 749.41 ms, tokens/sec 1377.08\n",
            "step41 , loss 6.43678092956543 , time 748.14 ms, tokens/sec 1379.42\n",
            "step42 , loss 6.459773063659668 , time 749.57 ms, tokens/sec 1376.79\n",
            "step43 , loss 6.220966339111328 , time 748.18 ms, tokens/sec 1379.34\n",
            "step44 , loss 6.161264419555664 , time 749.14 ms, tokens/sec 1377.57\n",
            "step45 , loss 6.238097190856934 , time 747.91 ms, tokens/sec 1379.85\n",
            "step46 , loss 6.349061965942383 , time 748.48 ms, tokens/sec 1378.79\n",
            "step47 , loss 6.326967239379883 , time 748.56 ms, tokens/sec 1378.65\n",
            "step48 , loss 6.2266845703125 , time 749.07 ms, tokens/sec 1377.71\n",
            "step49 , loss 6.10673713684082 , time 749.51 ms, tokens/sec 1376.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMt73tFWV_A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TORCH.COMPILE"
      ],
      "metadata": {
        "id": "eyN00vlAWCw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "train_loader = DataLoaderLite(B=8, T=1024)\n",
        "# torch.set_float32_matmul_precision('high')\n",
        "model=GPT(GPTConfig())\n",
        "model.to(device)\n",
        "model = torch.compile(model)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "for i in range(50):\n",
        "  t0=time.time()\n",
        "  x, y = train_loader.next_batch()\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  torch.cuda.synchronize()\n",
        "  t1=time.time()\n",
        "  dt = (t1-t0) * 1000\n",
        "  tokens_per_sec = (train_loader.B + train_loader.T) / (t1-t0)\n",
        "  print(f\"step{i} , loss {loss.item()} , time {dt:.2f} ms, tokens/sec {tokens_per_sec:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNT3d-w4V-80",
        "outputId": "cc375c9f-9a5e-4a57-9c84-d311c1ab1682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 338025 tokens\n",
            "1 epoch = 41 batches\n",
            "step0 , loss 10.98843002319336 , time 31047.56 ms, tokens/sec 33.24\n",
            "step1 , loss 9.501754760742188 , time 345.52 ms, tokens/sec 2986.79\n",
            "step2 , loss 8.811883926391602 , time 350.64 ms, tokens/sec 2943.21\n",
            "step3 , loss 8.60702133178711 , time 349.57 ms, tokens/sec 2952.22\n",
            "step4 , loss 8.446940422058105 , time 346.24 ms, tokens/sec 2980.63\n",
            "step5 , loss 8.384843826293945 , time 342.70 ms, tokens/sec 3011.41\n",
            "step6 , loss 8.318967819213867 , time 347.51 ms, tokens/sec 2969.73\n",
            "step7 , loss 7.9779558181762695 , time 348.63 ms, tokens/sec 2960.14\n",
            "step8 , loss 7.697345733642578 , time 342.86 ms, tokens/sec 3009.95\n",
            "step9 , loss 7.652235984802246 , time 348.52 ms, tokens/sec 2961.09\n",
            "step10 , loss 7.6265668869018555 , time 352.67 ms, tokens/sec 2926.27\n",
            "step11 , loss 7.456626892089844 , time 348.47 ms, tokens/sec 2961.48\n",
            "step12 , loss 7.3813934326171875 , time 353.07 ms, tokens/sec 2922.89\n",
            "step13 , loss 7.15690279006958 , time 352.87 ms, tokens/sec 2924.56\n",
            "step14 , loss 7.055956840515137 , time 345.49 ms, tokens/sec 2987.04\n",
            "step15 , loss 6.856966018676758 , time 354.30 ms, tokens/sec 2912.82\n",
            "step16 , loss 6.760332107543945 , time 351.36 ms, tokens/sec 2937.12\n",
            "step17 , loss 6.772274494171143 , time 352.90 ms, tokens/sec 2924.36\n",
            "step18 , loss 6.65046501159668 , time 353.96 ms, tokens/sec 2915.61\n",
            "step19 , loss 6.485589027404785 , time 351.28 ms, tokens/sec 2937.81\n",
            "step20 , loss 6.544715881347656 , time 353.47 ms, tokens/sec 2919.62\n",
            "step21 , loss 6.388439655303955 , time 352.40 ms, tokens/sec 2928.48\n",
            "step22 , loss 6.488442420959473 , time 353.12 ms, tokens/sec 2922.52\n",
            "step23 , loss 6.338450908660889 , time 354.44 ms, tokens/sec 2911.66\n",
            "step24 , loss 6.332170486450195 , time 353.18 ms, tokens/sec 2922.06\n",
            "step25 , loss 6.391902446746826 , time 352.84 ms, tokens/sec 2924.82\n",
            "step26 , loss 6.599626541137695 , time 354.90 ms, tokens/sec 2907.82\n",
            "step27 , loss 6.48133659362793 , time 353.90 ms, tokens/sec 2916.04\n",
            "step28 , loss 6.715150356292725 , time 353.21 ms, tokens/sec 2921.75\n",
            "step29 , loss 6.505034446716309 , time 354.47 ms, tokens/sec 2911.41\n",
            "step30 , loss 6.4968438148498535 , time 357.41 ms, tokens/sec 2887.47\n",
            "step31 , loss 6.498530864715576 , time 356.37 ms, tokens/sec 2895.89\n",
            "step32 , loss 6.3481831550598145 , time 353.55 ms, tokens/sec 2918.99\n",
            "step33 , loss 6.683195114135742 , time 353.23 ms, tokens/sec 2921.59\n",
            "step34 , loss 6.534754753112793 , time 356.73 ms, tokens/sec 2892.96\n",
            "step35 , loss 6.411908149719238 , time 356.14 ms, tokens/sec 2897.74\n",
            "step36 , loss 6.452384948730469 , time 355.83 ms, tokens/sec 2900.25\n",
            "step37 , loss 6.445199966430664 , time 351.65 ms, tokens/sec 2934.70\n",
            "step38 , loss 6.2344560623168945 , time 356.12 ms, tokens/sec 2897.88\n",
            "step39 , loss 6.263855457305908 , time 358.60 ms, tokens/sec 2877.82\n",
            "step40 , loss 6.528392314910889 , time 359.41 ms, tokens/sec 2871.37\n",
            "step41 , loss 6.277641296386719 , time 357.90 ms, tokens/sec 2883.46\n",
            "step42 , loss 6.304069995880127 , time 358.09 ms, tokens/sec 2881.99\n",
            "step43 , loss 6.05498743057251 , time 357.38 ms, tokens/sec 2887.68\n",
            "step44 , loss 5.998044013977051 , time 355.90 ms, tokens/sec 2899.71\n",
            "step45 , loss 6.057521343231201 , time 355.09 ms, tokens/sec 2906.31\n",
            "step46 , loss 6.17888069152832 , time 355.62 ms, tokens/sec 2901.98\n",
            "step47 , loss 6.1392316818237305 , time 359.52 ms, tokens/sec 2870.51\n",
            "step48 , loss 6.02908992767334 , time 359.03 ms, tokens/sec 2874.42\n",
            "step49 , loss 5.890707015991211 , time 358.67 ms, tokens/sec 2877.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with flash attn"
      ],
      "metadata": {
        "id": "LNKv7_Oba4IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "train_loader = DataLoaderLite(B=8, T=1024)\n",
        "# torch.set_float32_matmul_precision('high')\n",
        "model=GPT(GPTConfig())\n",
        "model.to(device)\n",
        "model = torch.compile(model)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "for i in range(50):\n",
        "  t0=time.time()\n",
        "  x, y = train_loader.next_batch()\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  torch.cuda.synchronize()\n",
        "  t1=time.time()\n",
        "  dt = (t1-t0) * 1000\n",
        "  tokens_per_sec = (train_loader.B + train_loader.T) / (t1-t0)\n",
        "  print(f\"step{i} , loss {loss.item()} , time {dt:.2f} ms, tokens/sec {tokens_per_sec:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ahw0whm1V-6k",
        "outputId": "36a8e205-2b2e-4b86-9d9c-288d1b8ac3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 338025 tokens\n",
            "1 epoch = 41 batches\n",
            "step0 , loss 11.025934219360352 , time 1656.06 ms, tokens/sec 623.17\n",
            "step1 , loss 9.580589294433594 , time 236.78 ms, tokens/sec 4358.49\n",
            "step2 , loss 9.052183151245117 , time 237.12 ms, tokens/sec 4352.19\n",
            "step3 , loss 8.705053329467773 , time 247.11 ms, tokens/sec 4176.29\n",
            "step4 , loss 8.576934814453125 , time 252.74 ms, tokens/sec 4083.20\n",
            "step5 , loss 8.457185745239258 , time 243.87 ms, tokens/sec 4231.76\n",
            "step6 , loss 8.398371696472168 , time 237.65 ms, tokens/sec 4342.49\n",
            "step7 , loss 8.109476089477539 , time 244.88 ms, tokens/sec 4214.23\n",
            "step8 , loss 7.8267903327941895 , time 247.62 ms, tokens/sec 4167.75\n",
            "step9 , loss 7.7667951583862305 , time 246.41 ms, tokens/sec 4188.17\n",
            "step10 , loss 7.740192890167236 , time 241.95 ms, tokens/sec 4265.34\n",
            "step11 , loss 7.55926513671875 , time 244.23 ms, tokens/sec 4225.56\n",
            "step12 , loss 7.518259048461914 , time 245.11 ms, tokens/sec 4210.43\n",
            "step13 , loss 7.288984775543213 , time 246.10 ms, tokens/sec 4193.34\n",
            "step14 , loss 7.174355983734131 , time 245.94 ms, tokens/sec 4196.08\n",
            "step15 , loss 6.9847211837768555 , time 244.14 ms, tokens/sec 4227.09\n",
            "step16 , loss 6.895357131958008 , time 246.25 ms, tokens/sec 4190.80\n",
            "step17 , loss 6.892436504364014 , time 247.64 ms, tokens/sec 4167.35\n",
            "step18 , loss 6.763436317443848 , time 244.29 ms, tokens/sec 4224.47\n",
            "step19 , loss 6.610531330108643 , time 244.62 ms, tokens/sec 4218.73\n",
            "step20 , loss 6.658645153045654 , time 247.63 ms, tokens/sec 4167.49\n",
            "step21 , loss 6.520234107971191 , time 248.48 ms, tokens/sec 4153.24\n",
            "step22 , loss 6.59055233001709 , time 244.91 ms, tokens/sec 4213.85\n",
            "step23 , loss 6.460455894470215 , time 247.32 ms, tokens/sec 4172.68\n",
            "step24 , loss 6.433602809906006 , time 249.18 ms, tokens/sec 4141.56\n",
            "step25 , loss 6.493185043334961 , time 248.53 ms, tokens/sec 4152.38\n",
            "step26 , loss 6.616909980773926 , time 247.34 ms, tokens/sec 4172.47\n",
            "step27 , loss 6.512841701507568 , time 243.95 ms, tokens/sec 4230.34\n",
            "step28 , loss 6.750434875488281 , time 249.92 ms, tokens/sec 4129.31\n",
            "step29 , loss 6.558879852294922 , time 246.80 ms, tokens/sec 4181.47\n",
            "step30 , loss 6.551164150238037 , time 246.80 ms, tokens/sec 4181.60\n",
            "step31 , loss 6.543529510498047 , time 250.76 ms, tokens/sec 4115.55\n",
            "step32 , loss 6.380763053894043 , time 249.07 ms, tokens/sec 4143.42\n",
            "step33 , loss 6.74670934677124 , time 250.84 ms, tokens/sec 4114.18\n",
            "step34 , loss 6.5823774337768555 , time 248.33 ms, tokens/sec 4155.73\n",
            "step35 , loss 6.471755504608154 , time 251.78 ms, tokens/sec 4098.74\n",
            "step36 , loss 6.5419535636901855 , time 248.89 ms, tokens/sec 4146.45\n",
            "step37 , loss 6.5504560470581055 , time 251.49 ms, tokens/sec 4103.52\n",
            "step38 , loss 6.341597080230713 , time 246.33 ms, tokens/sec 4189.51\n",
            "step39 , loss 6.374425888061523 , time 253.81 ms, tokens/sec 4065.95\n",
            "step40 , loss 6.597843170166016 , time 247.89 ms, tokens/sec 4163.11\n",
            "step41 , loss 6.351129055023193 , time 254.36 ms, tokens/sec 4057.25\n",
            "step42 , loss 6.426143646240234 , time 249.46 ms, tokens/sec 4136.89\n",
            "step43 , loss 6.124259948730469 , time 254.83 ms, tokens/sec 4049.71\n",
            "step44 , loss 6.065757751464844 , time 250.31 ms, tokens/sec 4122.90\n",
            "step45 , loss 6.139144420623779 , time 253.11 ms, tokens/sec 4077.35\n",
            "step46 , loss 6.263175010681152 , time 251.15 ms, tokens/sec 4109.11\n",
            "step47 , loss 6.2260422706604 , time 253.47 ms, tokens/sec 4071.55\n",
            "step48 , loss 6.146703720092773 , time 250.85 ms, tokens/sec 4114.08\n",
            "step49 , loss 5.999783515930176 , time 252.30 ms, tokens/sec 4090.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NIce numbers / vocab size"
      ],
      "metadata": {
        "id": "cCXAZqa8cjU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "train_loader = DataLoaderLite(B=8, T=1024)\n",
        "# torch.set_float32_matmul_precision('high')\n",
        "model=GPT(GPTConfig(vocab_size=50304))\n",
        "model.to(device)\n",
        "model = torch.compile(model)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "for i in range(50):\n",
        "  t0=time.time()\n",
        "  x, y = train_loader.next_batch()\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  torch.cuda.synchronize()\n",
        "  t1=time.time()\n",
        "  dt = (t1-t0) * 1000\n",
        "  tokens_per_sec = (train_loader.B + train_loader.T) / (t1-t0)\n",
        "  print(f\"step{i} , loss {loss.item()} , time {dt:.2f} ms, tokens/sec {tokens_per_sec:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPq5A6XzV-4F",
        "outputId": "f96064aa-73f5-4371-d6e1-ecf7eb60645d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 338025 tokens\n",
            "1 epoch = 41 batches\n",
            "step0 , loss 10.879960060119629 , time 22362.86 ms, tokens/sec 46.15\n",
            "step1 , loss 9.449729919433594 , time 231.75 ms, tokens/sec 4452.99\n",
            "step2 , loss 8.74146842956543 , time 234.81 ms, tokens/sec 4395.00\n",
            "step3 , loss 8.783228874206543 , time 240.61 ms, tokens/sec 4289.07\n",
            "step4 , loss 8.411894798278809 , time 242.26 ms, tokens/sec 4259.87\n",
            "step5 , loss 8.378988265991211 , time 228.68 ms, tokens/sec 4512.76\n",
            "step6 , loss 8.351465225219727 , time 233.57 ms, tokens/sec 4418.41\n",
            "step7 , loss 7.979005336761475 , time 234.17 ms, tokens/sec 4407.08\n",
            "step8 , loss 7.680255889892578 , time 244.85 ms, tokens/sec 4214.87\n",
            "step9 , loss 7.659424304962158 , time 235.12 ms, tokens/sec 4389.16\n",
            "step10 , loss 7.673420429229736 , time 233.66 ms, tokens/sec 4416.72\n",
            "step11 , loss 7.473594665527344 , time 239.59 ms, tokens/sec 4307.27\n",
            "step12 , loss 7.435180187225342 , time 243.04 ms, tokens/sec 4246.29\n",
            "step13 , loss 7.23840856552124 , time 240.80 ms, tokens/sec 4285.64\n",
            "step14 , loss 7.141092300415039 , time 237.84 ms, tokens/sec 4339.09\n",
            "step15 , loss 6.978565216064453 , time 240.55 ms, tokens/sec 4290.09\n",
            "step16 , loss 6.86184024810791 , time 241.54 ms, tokens/sec 4272.59\n",
            "step17 , loss 6.856351375579834 , time 241.76 ms, tokens/sec 4268.72\n",
            "step18 , loss 6.740754127502441 , time 238.86 ms, tokens/sec 4320.59\n",
            "step19 , loss 6.622786998748779 , time 233.56 ms, tokens/sec 4418.55\n",
            "step20 , loss 6.674576282501221 , time 240.73 ms, tokens/sec 4286.89\n",
            "step21 , loss 6.550614356994629 , time 243.32 ms, tokens/sec 4241.33\n",
            "step22 , loss 6.629467010498047 , time 240.21 ms, tokens/sec 4296.17\n",
            "step23 , loss 6.5187087059021 , time 240.22 ms, tokens/sec 4295.98\n",
            "step24 , loss 6.484066963195801 , time 240.14 ms, tokens/sec 4297.42\n",
            "step25 , loss 6.532788276672363 , time 240.59 ms, tokens/sec 4289.51\n",
            "step26 , loss 6.627884864807129 , time 240.27 ms, tokens/sec 4295.20\n",
            "step27 , loss 6.523525714874268 , time 241.76 ms, tokens/sec 4268.73\n",
            "step28 , loss 6.756401062011719 , time 239.37 ms, tokens/sec 4311.31\n",
            "step29 , loss 6.552430152893066 , time 238.00 ms, tokens/sec 4336.15\n",
            "step30 , loss 6.558310031890869 , time 239.79 ms, tokens/sec 4303.75\n",
            "step31 , loss 6.551558494567871 , time 241.82 ms, tokens/sec 4267.68\n",
            "step32 , loss 6.382063865661621 , time 239.83 ms, tokens/sec 4302.96\n",
            "step33 , loss 6.7532806396484375 , time 240.23 ms, tokens/sec 4295.95\n",
            "step34 , loss 6.580185890197754 , time 239.07 ms, tokens/sec 4316.77\n",
            "step35 , loss 6.475249767303467 , time 240.08 ms, tokens/sec 4298.54\n",
            "step36 , loss 6.524886131286621 , time 242.10 ms, tokens/sec 4262.66\n",
            "step37 , loss 6.53542423248291 , time 239.17 ms, tokens/sec 4314.85\n",
            "step38 , loss 6.354986667633057 , time 243.07 ms, tokens/sec 4245.67\n",
            "step39 , loss 6.380897521972656 , time 243.42 ms, tokens/sec 4239.55\n",
            "step40 , loss 6.606577396392822 , time 245.14 ms, tokens/sec 4209.79\n",
            "step41 , loss 6.3609843254089355 , time 242.55 ms, tokens/sec 4254.85\n",
            "step42 , loss 6.429946422576904 , time 242.21 ms, tokens/sec 4260.79\n",
            "step43 , loss 6.15673303604126 , time 241.15 ms, tokens/sec 4279.47\n",
            "step44 , loss 6.100228309631348 , time 240.71 ms, tokens/sec 4287.24\n",
            "step45 , loss 6.173757553100586 , time 239.99 ms, tokens/sec 4300.16\n",
            "step46 , loss 6.290382385253906 , time 239.44 ms, tokens/sec 4309.99\n",
            "step47 , loss 6.247769355773926 , time 239.99 ms, tokens/sec 4300.17\n",
            "step48 , loss 6.144560813903809 , time 239.77 ms, tokens/sec 4304.13\n",
            "step49 , loss 6.007992744445801 , time 238.97 ms, tokens/sec 4318.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cI55yyO3dqgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# further optimizations based on GPT 3"
      ],
      "metadata": {
        "id": "EYl7mfPZdry-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "train_loader = DataLoaderLite(B=8, T=1024)\n",
        "# torch.set_float32_matmul_precision('high')\n",
        "model=GPT(GPTConfig(vocab_size=50304))\n",
        "model.to(device)\n",
        "model = torch.compile(model)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), eps=1e-8)\n",
        "for i in range(50):\n",
        "  t0=time.time()\n",
        "  x, y = train_loader.next_batch()\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "  loss.backward()\n",
        "  norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "  optimizer.step()\n",
        "  torch.cuda.synchronize()\n",
        "  t1=time.time()\n",
        "  dt = (t1-t0) * 1000\n",
        "  tokens_per_sec = (train_loader.B + train_loader.T) / (t1-t0)\n",
        "  print(f\"step{i} , loss {loss.item()} , time {dt:.2f} ms, tokens/sec {tokens_per_sec:.2f}, norm {norm :.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tFQskSydqcZ",
        "outputId": "bb7295dd-d948-4e70-8e80-44a2905d9fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 338025 tokens\n",
            "1 epoch = 41 batches\n",
            "step0 , loss 10.949409484863281 , time 365.43 ms, tokens/sec 2824.08, norm 27.0177\n",
            "step1 , loss 9.585895538330078 , time 232.29 ms, tokens/sec 4442.69, norm 8.7193\n",
            "step2 , loss 9.138595581054688 , time 237.14 ms, tokens/sec 4351.83, norm 9.0948\n",
            "step3 , loss 8.827247619628906 , time 238.49 ms, tokens/sec 4327.27, norm 4.1152\n",
            "step4 , loss 8.654638290405273 , time 250.53 ms, tokens/sec 4119.30, norm 3.6695\n",
            "step5 , loss 8.454200744628906 , time 249.86 ms, tokens/sec 4130.25, norm 2.6055\n",
            "step6 , loss 8.382661819458008 , time 241.86 ms, tokens/sec 4267.00, norm 2.0046\n",
            "step7 , loss 8.051900863647461 , time 238.51 ms, tokens/sec 4326.84, norm 2.3224\n",
            "step8 , loss 7.736559867858887 , time 246.16 ms, tokens/sec 4192.39, norm 1.6099\n",
            "step9 , loss 7.682575225830078 , time 247.60 ms, tokens/sec 4168.06, norm 1.8356\n",
            "step10 , loss 7.654802322387695 , time 246.47 ms, tokens/sec 4187.05, norm 1.9479\n",
            "step11 , loss 7.438798904418945 , time 244.07 ms, tokens/sec 4228.34, norm 1.5231\n",
            "step12 , loss 7.3780927658081055 , time 244.70 ms, tokens/sec 4217.49, norm 1.2088\n",
            "step13 , loss 7.11196756362915 , time 240.69 ms, tokens/sec 4287.75, norm 1.0542\n",
            "step14 , loss 6.992372512817383 , time 251.33 ms, tokens/sec 4106.20, norm 1.0154\n",
            "step15 , loss 6.77244758605957 , time 247.23 ms, tokens/sec 4174.29, norm 1.1117\n",
            "step16 , loss 6.688289642333984 , time 242.36 ms, tokens/sec 4258.19, norm 1.1147\n",
            "step17 , loss 6.672102928161621 , time 240.09 ms, tokens/sec 4298.33, norm 0.9841\n",
            "step18 , loss 6.573349952697754 , time 250.97 ms, tokens/sec 4112.01, norm 1.4296\n",
            "step19 , loss 6.394848823547363 , time 248.98 ms, tokens/sec 4144.92, norm 0.8627\n",
            "step20 , loss 6.4676971435546875 , time 249.21 ms, tokens/sec 4141.13, norm 1.2584\n",
            "step21 , loss 6.320976257324219 , time 241.46 ms, tokens/sec 4273.98, norm 1.2003\n",
            "step22 , loss 6.425416946411133 , time 242.63 ms, tokens/sec 4253.41, norm 0.9910\n",
            "step23 , loss 6.265676498413086 , time 243.86 ms, tokens/sec 4231.89, norm 0.8240\n",
            "step24 , loss 6.277561187744141 , time 248.90 ms, tokens/sec 4146.30, norm 1.1402\n",
            "step25 , loss 6.327713966369629 , time 246.45 ms, tokens/sec 4187.50, norm 0.8389\n",
            "step26 , loss 6.583209991455078 , time 242.65 ms, tokens/sec 4253.12, norm 1.5961\n",
            "step27 , loss 6.448182106018066 , time 248.10 ms, tokens/sec 4159.62, norm 1.4721\n",
            "step28 , loss 6.693682670593262 , time 248.62 ms, tokens/sec 4150.93, norm 1.0680\n",
            "step29 , loss 6.453638553619385 , time 245.42 ms, tokens/sec 4205.01, norm 0.9874\n",
            "step30 , loss 6.427082538604736 , time 249.33 ms, tokens/sec 4139.09, norm 0.7482\n",
            "step31 , loss 6.4187211990356445 , time 248.08 ms, tokens/sec 4159.90, norm 0.9431\n",
            "step32 , loss 6.308201789855957 , time 250.23 ms, tokens/sec 4124.26, norm 1.1806\n",
            "step33 , loss 6.576249122619629 , time 249.94 ms, tokens/sec 4129.00, norm 1.3903\n",
            "step34 , loss 6.428138732910156 , time 251.83 ms, tokens/sec 4098.07, norm 1.1539\n",
            "step35 , loss 6.334539413452148 , time 248.17 ms, tokens/sec 4158.40, norm 0.9376\n",
            "step36 , loss 6.359671115875244 , time 251.07 ms, tokens/sec 4110.42, norm 1.2220\n",
            "step37 , loss 6.382319450378418 , time 246.27 ms, tokens/sec 4190.58, norm 1.1396\n",
            "step38 , loss 6.146090984344482 , time 248.17 ms, tokens/sec 4158.37, norm 0.9827\n",
            "step39 , loss 6.171275615692139 , time 250.10 ms, tokens/sec 4126.41, norm 1.0644\n",
            "step40 , loss 6.4875383377075195 , time 248.41 ms, tokens/sec 4154.35, norm 1.3832\n",
            "step41 , loss 6.338294982910156 , time 250.69 ms, tokens/sec 4116.56, norm 1.1520\n",
            "step42 , loss 6.376099586486816 , time 247.42 ms, tokens/sec 4171.03, norm 1.2830\n",
            "step43 , loss 6.097620010375977 , time 252.07 ms, tokens/sec 4094.09, norm 1.2944\n",
            "step44 , loss 6.020007610321045 , time 248.06 ms, tokens/sec 4160.24, norm 1.2442\n",
            "step45 , loss 6.075869560241699 , time 252.57 ms, tokens/sec 4085.93, norm 1.1464\n",
            "step46 , loss 6.166780471801758 , time 248.95 ms, tokens/sec 4145.42, norm 0.8287\n",
            "step47 , loss 6.110201835632324 , time 249.04 ms, tokens/sec 4143.95, norm 1.2048\n",
            "step48 , loss 5.981688499450684 , time 247.06 ms, tokens/sec 4177.11, norm 0.9463\n",
            "step49 , loss 5.8309526443481445 , time 253.22 ms, tokens/sec 4075.54, norm 1.0559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lr schedule"
      ],
      "metadata": {
        "id": "Avl0HCeAe7bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time, math\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "train_loader = DataLoaderLite(B=8, T=1024)\n",
        "# torch.set_float32_matmul_precision('high')\n",
        "model=GPT(GPTConfig(vocab_size=50304))\n",
        "model.to(device).train()\n",
        "model = torch.compile(model)\n",
        "\n",
        "max_lr = 6e-4\n",
        "min_lr = max_lr * 0.1\n",
        "\n",
        "warmup_steps = 10\n",
        "max_steps = 50\n",
        "\n",
        "def get_lr(it):\n",
        "  if it < warmup_steps:\n",
        "    return max_lr * (it+1) / warmup_steps\n",
        "  if it > max_steps:\n",
        "    return min_lr\n",
        "\n",
        "  decay_ratio = (it-warmup_steps) / (max_steps-warmup_steps)\n",
        "\n",
        "  assert 0<=decay_ratio<=1\n",
        "  coeff = 0.5 *(1.0 + math.cos(math.pi * decay_ratio))\n",
        "  return min_lr + coeff * (max_lr - min_lr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), eps=1e-8)\n",
        "for step in range(max_steps):\n",
        "  t0=time.time()\n",
        "  x, y = train_loader.next_batch()\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "  optimizer.zero_grad()\n",
        "  with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "  loss.backward()\n",
        "  norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "  lr = get_lr(step)\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = lr\n",
        "\n",
        "  optimizer.step()\n",
        "  torch.cuda.synchronize()\n",
        "  t1=time.time()\n",
        "  dt = (t1-t0) * 1000\n",
        "  tokens_per_sec = (train_loader.B * train_loader.T) / (t1-t0)\n",
        "  print(f\"step{step} , loss {loss.item()} , time {dt:.2f} ms, tokens/sec {tokens_per_sec:.2f}, norm {norm :.4f}, lr {lr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppAPUtvbdqZn",
        "outputId": "9705e2f8-a73b-49d0-d22f-67df6f19871c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 338025 tokens\n",
            "1 epoch = 41 batches\n",
            "step0 , loss 11.047126770019531 , time 235.80 ms, tokens/sec 34741.90, norm 29.1180, lr 5.9999999999999995e-05\n",
            "step1 , loss 9.64242172241211 , time 234.11 ms, tokens/sec 34991.80, norm 9.5832, lr 0.00011999999999999999\n",
            "step2 , loss 9.007974624633789 , time 235.72 ms, tokens/sec 34753.32, norm 5.7911, lr 0.00017999999999999998\n",
            "step3 , loss 9.886116027832031 , time 244.37 ms, tokens/sec 33523.46, norm 10.5479, lr 0.00023999999999999998\n",
            "step4 , loss 9.111015319824219 , time 253.28 ms, tokens/sec 32344.24, norm 4.3315, lr 0.0003\n",
            "step5 , loss 8.721638679504395 , time 248.93 ms, tokens/sec 32909.04, norm 3.1822, lr 0.00035999999999999997\n",
            "step6 , loss 8.648611068725586 , time 237.93 ms, tokens/sec 34430.01, norm 4.0620, lr 0.00041999999999999996\n",
            "step7 , loss 8.237208366394043 , time 240.11 ms, tokens/sec 34118.01, norm 4.0748, lr 0.00047999999999999996\n",
            "step8 , loss 7.776317119598389 , time 245.07 ms, tokens/sec 33427.54, norm 1.7705, lr 0.0005399999999999999\n",
            "step9 , loss 7.627695560455322 , time 245.78 ms, tokens/sec 33330.59, norm 2.3075, lr 0.0006\n",
            "step10 , loss 7.420386791229248 , time 247.47 ms, tokens/sec 33102.60, norm 2.2184, lr 0.0005999999999999998\n",
            "step11 , loss 7.137991428375244 , time 242.72 ms, tokens/sec 33750.21, norm 1.3545, lr 0.0005991676801079444\n",
            "step12 , loss 7.028983116149902 , time 243.79 ms, tokens/sec 33602.01, norm 1.4208, lr 0.0005966758519606872\n",
            "step13 , loss 6.761631011962891 , time 248.85 ms, tokens/sec 32919.57, norm 1.0095, lr 0.0005925398785073725\n",
            "step14 , loss 6.649838447570801 , time 247.82 ms, tokens/sec 33056.55, norm 0.9268, lr 0.0005867852593996914\n",
            "step15 , loss 6.497086524963379 , time 241.71 ms, tokens/sec 33892.33, norm 1.8954, lr 0.0005794474737780473\n",
            "step16 , loss 6.590546131134033 , time 248.35 ms, tokens/sec 32986.22, norm 1.3178, lr 0.0005705717615308592\n",
            "step17 , loss 6.673452854156494 , time 249.03 ms, tokens/sec 32896.28, norm 2.1546, lr 0.0005602128443756048\n",
            "step18 , loss 6.605930328369141 , time 244.94 ms, tokens/sec 33444.30, norm 34.2366, lr 0.0005484345884812357\n",
            "step19 , loss 6.465422630310059 , time 251.08 ms, tokens/sec 32626.55, norm 1.7570, lr 0.0005353096107120083\n",
            "step20 , loss 6.5830512046813965 , time 244.57 ms, tokens/sec 33494.90, norm 1.5443, lr 0.0005209188309203677\n",
            "step21 , loss 6.368956089019775 , time 250.08 ms, tokens/sec 32756.94, norm 1.6261, lr 0.0005053509730491494\n",
            "step22 , loss 6.468074321746826 , time 247.85 ms, tokens/sec 33052.58, norm 1.2934, lr 0.0004887020181189676\n",
            "step23 , loss 6.266880035400391 , time 246.17 ms, tokens/sec 33277.65, norm 1.1565, lr 0.0004710746124733061\n",
            "step24 , loss 6.332430839538574 , time 253.24 ms, tokens/sec 32349.11, norm 2.2227, lr 0.0004525774349296775\n",
            "step25 , loss 6.352785110473633 , time 244.90 ms, tokens/sec 33450.68, norm 1.6597, lr 0.00043332452673857416\n",
            "step26 , loss 6.660555839538574 , time 250.65 ms, tokens/sec 32682.88, norm 1.4536, lr 0.00041343458848123576\n",
            "step27 , loss 6.499528884887695 , time 246.65 ms, tokens/sec 33212.54, norm 1.1264, lr 0.00039303024824109445\n",
            "step28 , loss 6.780679702758789 , time 252.74 ms, tokens/sec 32413.17, norm 1.0245, lr 0.0003722373055608623\n",
            "step29 , loss 6.540627479553223 , time 246.07 ms, tokens/sec 33291.09, norm 1.0109, lr 0.0003511839558465181\n",
            "step30 , loss 6.470636367797852 , time 250.61 ms, tokens/sec 32688.88, norm 0.8287, lr 0.00032999999999999994\n",
            "step31 , loss 6.46602725982666 , time 249.11 ms, tokens/sec 32885.29, norm 0.9703, lr 0.0003088160441534818\n",
            "step32 , loss 6.305628776550293 , time 251.85 ms, tokens/sec 32526.70, norm 1.1833, lr 0.0002877626944391376\n",
            "step33 , loss 6.578577041625977 , time 248.55 ms, tokens/sec 32959.52, norm 0.9951, lr 0.0002669697517589056\n",
            "step34 , loss 6.409862518310547 , time 251.63 ms, tokens/sec 32555.23, norm 0.9839, lr 0.0002465654115187642\n",
            "step35 , loss 6.324698448181152 , time 246.27 ms, tokens/sec 33264.41, norm 0.8299, lr 0.00022667547326142573\n",
            "step36 , loss 6.392388343811035 , time 249.39 ms, tokens/sec 32847.85, norm 1.0573, lr 0.00020742256507032234\n",
            "step37 , loss 6.408392906188965 , time 251.17 ms, tokens/sec 32614.94, norm 0.9539, lr 0.00018892538752669378\n",
            "step38 , loss 6.194252014160156 , time 253.24 ms, tokens/sec 32349.02, norm 0.9346, lr 0.00017129798188103226\n",
            "step39 , loss 6.250319480895996 , time 249.81 ms, tokens/sec 32793.30, norm 1.0206, lr 0.00015464902695085044\n",
            "step40 , loss 6.468325614929199 , time 251.44 ms, tokens/sec 32580.02, norm 1.2662, lr 0.00013908116907963218\n",
            "step41 , loss 6.297199249267578 , time 247.91 ms, tokens/sec 33044.44, norm 1.2255, lr 0.00012469038928799163\n",
            "step42 , loss 6.343682289123535 , time 253.01 ms, tokens/sec 32377.98, norm 1.3720, lr 0.00011156541151876421\n",
            "step43 , loss 6.050009727478027 , time 251.94 ms, tokens/sec 32516.32, norm 1.3983, lr 9.97871556243951e-05\n",
            "step44 , loss 6.005373954772949 , time 252.41 ms, tokens/sec 32454.77, norm 0.9523, lr 8.942823846914069e-05\n",
            "step45 , loss 6.074668884277344 , time 253.31 ms, tokens/sec 32339.49, norm 0.9226, lr 8.055252622195258e-05\n",
            "step46 , loss 6.145956039428711 , time 251.12 ms, tokens/sec 32621.75, norm 0.7830, lr 7.321474060030853e-05\n",
            "step47 , loss 6.034445285797119 , time 239.44 ms, tokens/sec 34213.58, norm 1.0846, lr 6.746012149262733e-05\n",
            "step48 , loss 5.93212890625 , time 257.40 ms, tokens/sec 31826.27, norm 0.8417, lr 6.332414803931283e-05\n",
            "step49 , loss 5.807844161987305 , time 255.91 ms, tokens/sec 32011.59, norm 0.9577, lr 6.083231989205545e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad accumulation"
      ],
      "metadata": {
        "id": "A6EjCDnLEG4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time, math\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "train_loader = DataLoaderLite(B=8, T=1024)\n",
        "# torch.set_float32_matmul_precision('high')\n",
        "model=GPT(GPTConfig(vocab_size=50304))\n",
        "model.to(device).train()\n",
        "model = torch.compile(model)\n",
        "\n",
        "max_lr = 6e-4\n",
        "min_lr = max_lr * 0.1\n",
        "\n",
        "warmup_steps = 10\n",
        "max_steps = 50\n",
        "\n",
        "total_batch_size = 524288\n",
        "B = 8\n",
        "T = 1024\n",
        "\n",
        "assert total_batch_size % (B*T) == 0\n",
        "grad_acc_steps = total_batch_size // (B*T)\n",
        "\n",
        "def get_lr(it):\n",
        "  if it < warmup_steps:\n",
        "    return max_lr * (it+1) / warmup_steps\n",
        "  if it > max_steps:\n",
        "    return min_lr\n",
        "\n",
        "  decay_ratio = (it-warmup_steps) / (max_steps-warmup_steps)\n",
        "\n",
        "  assert 0<=decay_ratio<=1\n",
        "  coeff = 0.5 *(1.0 + math.cos(math.pi * decay_ratio))\n",
        "  return min_lr + coeff * (max_lr - min_lr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), eps=1e-8)\n",
        "for step in range(max_steps):\n",
        "  t0=time.time()\n",
        "  x, y = train_loader.next_batch()\n",
        "  loss_accum = 0.0\n",
        "  for microstep in range(grad_acc_steps):\n",
        "\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
        "      logits, loss = model(x, y)\n",
        "    loss = loss/grad_acc_steps\n",
        "    loss_accum += loss.detach()\n",
        "    loss.backward()\n",
        "\n",
        "\n",
        "  norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "  lr = get_lr(step)\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = lr\n",
        "\n",
        "  optimizer.step()\n",
        "  torch.cuda.synchronize()\n",
        "  t1=time.time()\n",
        "  dt = (t1-t0) * 1000\n",
        "  tokens_per_sec = (train_loader.B * train_loader.T * grad_acc_steps) / (t1-t0)\n",
        "  print(f\"step{step} , loss {loss_accum.item()} , time {dt:.2f} ms, tokens/sec {tokens_per_sec:.2f}, norm {norm :.4f}, lr {lr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjPfvlkfe7Ks",
        "outputId": "0f0a1083-a9f4-4623-a0d5-78f9659b89c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 338025 tokens\n",
            "1 epoch = 41 batches\n",
            "step0 , loss 11.004355430603027 , time 13984.99 ms, tokens/sec 37489.33, norm 0.4644, lr 5.9999999999999995e-05\n",
            "step1 , loss 9.662590980529785 , time 13962.02 ms, tokens/sec 37551.01, norm 0.1462, lr 0.00011999999999999999\n",
            "step2 , loss 8.993795394897461 , time 13593.30 ms, tokens/sec 38569.59, norm 0.0883, lr 0.00017999999999999998\n",
            "step3 , loss 9.354405403137207 , time 13479.50 ms, tokens/sec 38895.20, norm 0.1276, lr 0.00023999999999999998\n",
            "step4 , loss 8.83443832397461 , time 13311.05 ms, tokens/sec 39387.42, norm 0.0630, lr 0.0003\n",
            "step5 , loss 8.700010299682617 , time 13271.96 ms, tokens/sec 39503.44, norm 0.0363, lr 0.00035999999999999997\n",
            "step6 , loss 8.677406311035156 , time 13321.60 ms, tokens/sec 39356.24, norm 0.0684, lr 0.00041999999999999996\n",
            "step7 , loss 8.201203346252441 , time 13417.04 ms, tokens/sec 39076.28, norm 0.0457, lr 0.00047999999999999996\n",
            "step8 , loss 7.775548934936523 , time 13458.12 ms, tokens/sec 38957.01, norm 0.0274, lr 0.0005399999999999999\n",
            "step9 , loss 7.631897449493408 , time 13406.60 ms, tokens/sec 39106.71, norm 0.0349, lr 0.0006\n",
            "step10 , loss 7.5411057472229 , time 13357.31 ms, tokens/sec 39251.01, norm 0.0501, lr 0.0005999999999999998\n",
            "step11 , loss 7.276055335998535 , time 13322.82 ms, tokens/sec 39352.64, norm 0.0403, lr 0.0005991676801079444\n",
            "step12 , loss 7.162627696990967 , time 13328.25 ms, tokens/sec 39336.59, norm 0.0246, lr 0.0005966758519606872\n",
            "step13 , loss 6.91475772857666 , time 13330.21 ms, tokens/sec 39330.82, norm 0.0160, lr 0.0005925398785073725\n",
            "step14 , loss 6.823671340942383 , time 13323.12 ms, tokens/sec 39351.75, norm 0.0198, lr 0.0005867852593996914\n",
            "step15 , loss 6.661293983459473 , time 13341.29 ms, tokens/sec 39298.14, norm 0.0223, lr 0.0005794474737780473\n",
            "step16 , loss 6.720694541931152 , time 13401.88 ms, tokens/sec 39120.49, norm 0.0215, lr 0.0005705717615308592\n",
            "step17 , loss 6.772116661071777 , time 13400.22 ms, tokens/sec 39125.31, norm 0.0238, lr 0.0005602128443756048\n",
            "step18 , loss 6.679251670837402 , time 13398.36 ms, tokens/sec 39130.75, norm 0.0266, lr 0.0005484345884812357\n",
            "step19 , loss 6.525052547454834 , time 13375.22 ms, tokens/sec 39198.45, norm 0.0262, lr 0.0005353096107120083\n",
            "step20 , loss 6.626342296600342 , time 13393.63 ms, tokens/sec 39144.58, norm 0.0207, lr 0.0005209188309203677\n",
            "step21 , loss 6.449636936187744 , time 13403.80 ms, tokens/sec 39114.88, norm 0.0165, lr 0.0005053509730491494\n",
            "step22 , loss 6.575234413146973 , time 13405.95 ms, tokens/sec 39108.60, norm 0.0140, lr 0.0004887020181189676\n",
            "step23 , loss 6.425475597381592 , time 13410.60 ms, tokens/sec 39095.04, norm 0.0179, lr 0.0004710746124733061\n",
            "step24 , loss 6.430121898651123 , time 13412.55 ms, tokens/sec 39089.36, norm 0.0256, lr 0.0004525774349296775\n",
            "step25 , loss 6.502096652984619 , time 13427.25 ms, tokens/sec 39046.56, norm 0.0270, lr 0.00043332452673857416\n",
            "step26 , loss 6.754279613494873 , time 13428.52 ms, tokens/sec 39042.87, norm 0.0267, lr 0.00041343458848123576\n",
            "step27 , loss 6.630867958068848 , time 13434.90 ms, tokens/sec 39024.33, norm 0.0285, lr 0.00039303024824109445\n",
            "step28 , loss 6.906252384185791 , time 13438.78 ms, tokens/sec 39013.08, norm 0.0180, lr 0.0003722373055608623\n",
            "step29 , loss 6.667482376098633 , time 13459.71 ms, tokens/sec 38952.39, norm 0.0142, lr 0.0003511839558465181\n",
            "step30 , loss 6.640480995178223 , time 13446.81 ms, tokens/sec 38989.77, norm 0.0148, lr 0.00032999999999999994\n",
            "step31 , loss 6.613379955291748 , time 13466.94 ms, tokens/sec 38931.49, norm 0.0141, lr 0.0003088160441534818\n",
            "step32 , loss 6.452761173248291 , time 13476.07 ms, tokens/sec 38905.10, norm 0.0170, lr 0.0002877626944391376\n",
            "step33 , loss 6.808532238006592 , time 13486.96 ms, tokens/sec 38873.69, norm 0.0164, lr 0.0002669697517589056\n",
            "step34 , loss 6.646994590759277 , time 13495.47 ms, tokens/sec 38849.18, norm 0.0158, lr 0.0002465654115187642\n",
            "step35 , loss 6.523526668548584 , time 13473.78 ms, tokens/sec 38911.72, norm 0.0130, lr 0.00022667547326142573\n",
            "step36 , loss 6.587881565093994 , time 13509.44 ms, tokens/sec 38809.01, norm 0.0198, lr 0.00020742256507032234\n",
            "step37 , loss 6.574728488922119 , time 13552.20 ms, tokens/sec 38686.55, norm 0.0176, lr 0.00018892538752669378\n",
            "step38 , loss 6.488821506500244 , time 13586.35 ms, tokens/sec 38589.31, norm 0.0737, lr 0.00017129798188103226\n",
            "step39 , loss 6.467224597930908 , time 13495.25 ms, tokens/sec 38849.83, norm 0.0163, lr 0.00015464902695085044\n",
            "step40 , loss 6.656700611114502 , time 13474.18 ms, tokens/sec 38910.58, norm 0.0165, lr 0.00013908116907963218\n",
            "step41 , loss 6.368448257446289 , time 13475.98 ms, tokens/sec 38905.38, norm 0.0167, lr 0.00012469038928799163\n",
            "step42 , loss 6.406472682952881 , time 13475.60 ms, tokens/sec 38906.46, norm 0.0195, lr 0.00011156541151876421\n",
            "step43 , loss 6.140532493591309 , time 13474.72 ms, tokens/sec 38909.02, norm 0.0239, lr 9.97871556243951e-05\n",
            "step44 , loss 6.087767601013184 , time 13474.45 ms, tokens/sec 38909.80, norm 0.0177, lr 8.942823846914069e-05\n",
            "step45 , loss 6.181253433227539 , time 13486.13 ms, tokens/sec 38876.10, norm 0.0154, lr 8.055252622195258e-05\n",
            "step46 , loss 6.279592514038086 , time 13474.67 ms, tokens/sec 38909.15, norm 0.0130, lr 7.321474060030853e-05\n",
            "step47 , loss 6.122741222381592 , time 13477.73 ms, tokens/sec 38900.33, norm 0.0152, lr 6.746012149262733e-05\n",
            "step48 , loss 6.062459468841553 , time 13473.64 ms, tokens/sec 38912.13, norm 0.0116, lr 6.332414803931283e-05\n",
            "step49 , loss 5.9321818351745605 , time 13476.36 ms, tokens/sec 38904.27, norm 0.0115, lr 6.083231989205545e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oWI6IXwre7Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mBZX9-2Ie7Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHQQyg7pe7A1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}